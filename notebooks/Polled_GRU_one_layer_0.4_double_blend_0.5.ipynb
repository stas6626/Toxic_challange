{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/stas/fastdata/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate\n",
    "from keras.layers import CuDNNGRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import Callback\n",
    "import nltk\n",
    "from numba import jit\n",
    "from gensim.models import FastText\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "EMBEDDING_FILE = '../data/crawl-300d-2M.vec'\n",
    "\n",
    "train = pd.read_csv('../data/train.csv.zip')\n",
    "train[\"comment_text\"] = train.comment_text.apply(lambda x: x[:800])\n",
    "test = pd.read_csv('../data/test.csv.zip')\n",
    "test[\"comment_text\"] = test.comment_text.apply(lambda x: x[:800])\n",
    "submission = pd.read_csv('../data/sample_submission.csv.zip')\n",
    "\n",
    "X_train = train[\"comment_text\"].fillna(\"fillna\").values\n",
    "y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\n",
    "X_test = test[\"comment_text\"].fillna(\"fillna\").values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lawer(sen):\n",
    "    count = 0\n",
    "    for i in sen:\n",
    "        if i.isupper():\n",
    "            count += 1\n",
    "    if len(sen) == 0: \n",
    "        return sen\n",
    "    if count/len(sen) > 0.2: \n",
    "        sen.append(\"gronker\")\n",
    "    return sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stamer(sen):\n",
    "    return list(map(st.stem,sen))\n",
    "st = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_to_sen(sen):\n",
    "    return \"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in sen]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(sen):\n",
    "    return text.text_to_word_sequence(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159571/159571 [00:02<00:00, 65906.16it/s]\n",
      "100%|██████████| 153164/153164 [00:03<00:00, 46993.10it/s]\n",
      "100%|██████████| 159571/159571 [00:03<00:00, 42071.14it/s]\n",
      "100%|██████████| 153164/153164 [00:03<00:00, 43295.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 s, sys: 2.28 s, total: 13.5 s\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tr = Parallel(n_jobs=16)(delayed(token)(x) for x in tqdm(X_train))\n",
    "tes = Parallel(n_jobs=16)(delayed(token)(x) for x in tqdm(X_test))\n",
    "#gro_tr = Parallel(n_jobs=16)(delayed(lawer)(x) for x in tqdm(tr))\n",
    "#gro_tes = Parallel(n_jobs=16)(delayed(lawer)(x) for x in tqdm(tes))\n",
    "#lem_tr = Parallel(n_jobs=16)(delayed(stamer)(x) for x in tqdm(gro_tr))\n",
    "#lem_tes = Parallel(n_jobs=16)(delayed(stamer)(x) for x in tqdm(gro_tes))\n",
    "keras_ready_tr = Parallel(n_jobs=16)(delayed(token_to_sen)(x) for x in tqdm(tr))\n",
    "keras_ready_tes = Parallel(n_jobs=16)(delayed(token_to_sen)(x) for x in tqdm(tes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0.05, 0.1, 0.25, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [08:10<24:32, 490.93s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in tqdm(a):\n",
    "    model = FastText(tes+tr, size=300, window=5, workers=16, iter=5,alpha=i)\n",
    "    model.save(f\"../models/FastText/Fasttest_alpha_{i}_5iter.gen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05, 0.1, 0.25, 0.5]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText.load(\"../models/FastText/Fasttest_alpha_0.5_5iter.gen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_vec = dict(zip(model.wv.index2word, model.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_features = 60000\n",
    "maxlen = 800\n",
    "embed_size = 300\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=max_features, lower=False)\n",
    "tokenizer.fit_on_texts(keras_ready_tr+keras_ready_tes)\n",
    "X_train = tokenizer.texts_to_sequences(keras_ready_tr)\n",
    "X_test = tokenizer.texts_to_sequences(keras_ready_tes)\n",
    "x_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 46s, sys: 2.61 s, total: 1min 49s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((np.zeros(2),np.zeros(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, embed_size*2))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector_crawl = embeddings_index.get(word)\n",
    "    embedding_vector_self = fast_vec.get(word)\n",
    "    if (embedding_vector_crawl is not None) and (embedding_vector_self is not None): \n",
    "        embedding_matrix[i] = np.hstack((embedding_vector_crawl,embedding_vector_self))\n",
    "        \n",
    "    elif (embedding_vector_crawl is None) and (embedding_vector_self is not None):\n",
    "        embedding_matrix[i] = np.hstack((np.zeros(300),embedding_vector_self))\n",
    "    \n",
    "    else: \n",
    "        embedding_matrix[i] = np.hstack((np.zeros(300),np.zeros(300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 600)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size*2, weights=[embedding_matrix])(inp)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    x = Bidirectional(CuDNNGRU(80, return_sequences=True))(x)\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    outp = Dense(6, activation=\"sigmoid\")(conc)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 151592 samples, validate on 7979 samples\n",
      "Epoch 1/1\n",
      "151592/151592 [==============================] - 210s 1ms/step - loss: 0.1056 - acc: 0.9678 - val_loss: 0.0601 - val_acc: 0.9792\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.881331 \n",
      "\n",
      "Train on 151592 samples, validate on 7979 samples\n",
      "Epoch 1/1\n",
      "151592/151592 [==============================] - 207s 1ms/step - loss: 0.0544 - acc: 0.9807 - val_loss: 0.0528 - val_acc: 0.9812\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.967567 \n",
      "\n",
      "Train on 151592 samples, validate on 7979 samples\n",
      "Epoch 1/1\n",
      "151592/151592 [==============================] - 203s 1ms/step - loss: 0.0480 - acc: 0.9823 - val_loss: 0.0519 - val_acc: 0.9808\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.973070 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 300\n",
    "\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.95, random_state=233)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "for epoch in range(1,10):\n",
    "    hist = model.fit(X_tra, y_tra, batch_size=batch_size, epochs=1, validation_data=(X_val, y_val),\n",
    "                     callbacks=[RocAuc], verbose=1)\n",
    "    model.save(f'../models/Polled_gru_one_layer_0.2_double_embedsize/alpha_0.5_{epoch}epoch.h5')\n",
    "\n",
    "    y_pred = model.predict(x_test, batch_size=200)\n",
    "    submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\n",
    "    submission.to_csv(f'../submits/Polled_gru_one_layer_0.2_double_embedsize/alpha_0.5_{epoch}epoch.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
